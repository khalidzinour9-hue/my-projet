import streamlit as st
import pickle
import re
import nltk
from nltk.corpus import stopwords


def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    stop_words = set(stopwords.words('english'))
    text = ' '.join([w for w in text.split() if w not in stop_words])
    return text

st.title("üì© D√©tecteur de Spam")
st.write("Pr√©disez si le message est un Spam ou un message Ham.")

message = st.text_area("‚úâÔ∏è Entrez votre message ici :")

try:
    model = pickle.load(open("spam_model.pkl", "rb"))
    vectorizer = pickle.load(open("tfidf.pkl", "rb"))
except FileNotFoundError:
    st.warning("‚ö†Ô∏è Les fichiers du mod√®le (spam_model.pkl / tfidf.pkl) sont introuvables. Veuillez ex√©cuter `train_model.py` pour les g√©n√©rer.")
    model = None
    vectorizer = None

if st.button("üîç Analyser"):
    if not message.strip():
        st.warning("‚ö†Ô∏è Veuillez entrer un message valide.")
    else:
        if model is None or vectorizer is None:
            st.error("‚ùå Fichiers du mod√®le manquants. Lancez `train_model.py` pour les cr√©er.")
        else:
            cleaned = clean_text(message)
            vec = vectorizer.transform([cleaned])
            pred = model.predict(vec)[0]
            if pred == 1:
                st.error("üî¥ Ce message est un SPAM.")
            else:
                st.success("üü¢ Ce message est HAM .")
