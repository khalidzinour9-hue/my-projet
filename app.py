import streamlit as st
import pickle
import re
import nltk
from nltk.corpus import stopwords


def clean_text(text):
    text = str(text).lower()
    text = re.sub(r'http\S+|www\S+', '', text)
    text = re.sub(r'[^a-zA-Z]', ' ', text)
    import nltk
# Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± Ø³ÙŠØ¶Ù…Ù† ØªÙ†Ø²ÙŠÙ„ Ù…ÙˆØ±Ø¯ 'stopwords' Ø¹Ù†Ø¯ ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
# Ø¥Ø°Ø§ ÙƒØ§Ù† Ø¨Ø§Ù„ÙØ¹Ù„ Ù…ÙˆØ¬ÙˆØ¯Ù‹Ø§ØŒ ÙÙ„Ù† ÙŠÙ‚ÙˆÙ… Ø¨ØªÙ†Ø²ÙŠÙ„Ù‡ Ù…Ø±Ø© Ø£Ø®Ø±Ù‰.
try:
    nltk.data.find('corpora/stopwords')
except nltk.downloader.DownloadError:
    nltk.download('stopwords')

# Ø§Ù„Ø¢Ù† Ø§Ù„ÙƒÙˆØ¯ ÙŠÙ…ÙƒÙ†Ù‡ Ø§Ù„Ø¹Ù…Ù„:
from nltk.corpus import stopwords
# ...
# stop_words = set(stopwords.words('english'))
    stop_words = set(stopwords.words('english'))
    text = ' '.join([w for w in text.split() if w not in stop_words])
    return text

st.title("ğŸ“© DÃ©tecteur de Spam")
st.write("PrÃ©disez si le message est un Spam ou un message Ham.")

message = st.text_area("âœ‰ï¸ Entrez votre message ici :")

try:
    model = pickle.load(open("spam_model.pkl", "rb"))
    vectorizer = pickle.load(open("tfidf.pkl", "rb"))
except FileNotFoundError:
    st.warning("âš ï¸ Les fichiers du modÃ¨le (spam_model.pkl / tfidf.pkl) sont introuvables. Veuillez exÃ©cuter `train_model.py` pour les gÃ©nÃ©rer.")
    model = None
    vectorizer = None

if st.button("ğŸ” Analyser"):
    if not message.strip():
        st.warning("âš ï¸ Veuillez entrer un message valide.")
    else:
        if model is None or vectorizer is None:
            st.error("âŒ Fichiers du modÃ¨le manquants. Lancez `train_model.py` pour les crÃ©er.")
        else:
            cleaned = clean_text(message)
            vec = vectorizer.transform([cleaned])
            pred = model.predict(vec)[0]
            if pred == 1:
                st.error("ğŸ”´ Ce message est un SPAM.")
            else:
                st.success("ğŸŸ¢ Ce message est HAM .")
